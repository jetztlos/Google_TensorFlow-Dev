<html>
<head>
<title>Vision_ImageClassification.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #8c8c8c; font-style: italic;}
.s1 { color: #080808;}
.s2 { color: #0033b3;}
.s3 { color: #067d17;}
.s4 { color: #1750eb;}
</style>
</head>
<body bgcolor="#ffffff">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#c0c0c0" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
Vision_ImageClassification.py</font>
</center></td></tr></table>
<pre><span class="s0"># From: https://www.tensorflow.org/tutorials/images/classification</span>
<span class="s0">## Setup</span>
<span class="s2">import </span><span class="s1">matplotlib.pyplot </span><span class="s2">as </span><span class="s1">plt</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">PIL</span>
<span class="s2">import </span><span class="s1">tensorflow </span><span class="s2">as </span><span class="s1">tf</span>

<span class="s2">from </span><span class="s1">tensorflow </span><span class="s2">import </span><span class="s1">keras</span>
<span class="s2">from </span><span class="s1">tensorflow.keras </span><span class="s2">import </span><span class="s1">layers</span>
<span class="s2">from </span><span class="s1">tensorflow.keras.models </span><span class="s2">import </span><span class="s1">Sequential</span>

<span class="s0">## Download and explore the dataset</span>
<span class="s2">import </span><span class="s1">pathlib</span>

<span class="s1">dataset_url = </span><span class="s3">&quot;https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz&quot;</span>
<span class="s1">data_dir = tf.keras.utils.get_file(</span><span class="s3">'flower_photos.tar'</span><span class="s1">, origin=dataset_url, extract=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s1">data_dir = pathlib.Path(data_dir).with_suffix(</span><span class="s3">''</span><span class="s1">)</span>

<span class="s1">image_count = len(list(data_dir.glob(</span><span class="s3">'*/*.jpg'</span><span class="s1">)))</span>
<span class="s1">print (image_count)</span>

<span class="s1">roses = list(data_dir.glob(</span><span class="s3">'roses/*'</span><span class="s1">))</span>
<span class="s1">PIL.Image.open(str(roses[</span><span class="s4">0</span><span class="s1">]))</span>

<span class="s1">PIL.Image.open(str(roses[</span><span class="s4">1</span><span class="s1">]))</span>

<span class="s1">tulips = list(data_dir.glob(</span><span class="s3">'tulips/*'</span><span class="s1">))</span>
<span class="s1">PIL.Image.open(str(tulips[</span><span class="s4">0</span><span class="s1">]))</span>

<span class="s1">PIL.Image.open(str(tulips[</span><span class="s4">1</span><span class="s1">]))</span>

<span class="s0">## Load data using a Keras utility</span>
<span class="s0">### Create a dataset</span>
<span class="s1">batch_size = </span><span class="s4">32</span>
<span class="s1">img_height = </span><span class="s4">180</span>
<span class="s1">img_width = </span><span class="s4">180</span>

<span class="s1">train_ds = tf.keras.utils.image_dataset_from_directory(data_dir,</span>
                                                       <span class="s1">validation_split=</span><span class="s4">0.2</span><span class="s1">,</span>
                                                       <span class="s1">subset=</span><span class="s3">&quot;training&quot;</span><span class="s1">,</span>
                                                       <span class="s1">seed=</span><span class="s4">123</span><span class="s1">,</span>
                                                       <span class="s1">image_size=(img_height, img_width),</span>
                                                       <span class="s1">batch_size=batch_size)</span>

<span class="s1">val_ds = tf.keras.utils.image_dataset_from_directory(data_dir,</span>
                                                     <span class="s1">validation_split=</span><span class="s4">0.2</span><span class="s1">,</span>
                                                     <span class="s1">subset=</span><span class="s3">&quot;validation&quot;</span><span class="s1">,</span>
                                                     <span class="s1">seed=</span><span class="s4">123</span><span class="s1">,</span>
                                                     <span class="s1">image_size=(img_height, img_width),</span>
                                                     <span class="s1">batch_size=batch_size)</span>

<span class="s1">class_names = train_ds.class_names</span>
<span class="s1">print(class_names)</span>

<span class="s0">## Visualize the data</span>
<span class="s2">import </span><span class="s1">matplotlib.pyplot </span><span class="s2">as </span><span class="s1">plt</span>

<span class="s1">plt.figure(figsize=(</span><span class="s4">10</span><span class="s1">, </span><span class="s4">10</span><span class="s1">))</span>
<span class="s2">for </span><span class="s1">images, labels </span><span class="s2">in </span><span class="s1">train_ds.take(</span><span class="s4">1</span><span class="s1">):</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">9</span><span class="s1">):</span>
        <span class="s1">ax = plt.subplot(</span><span class="s4">3</span><span class="s1">, </span><span class="s4">3</span><span class="s1">, i +</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">plt.imshow(images[i].numpy().astype(</span><span class="s3">&quot;uint8&quot;</span><span class="s1">))</span>
        <span class="s1">plt.title(class_names[labels[i]])</span>
        <span class="s1">plt.axis(</span><span class="s3">&quot;off&quot;</span><span class="s1">)</span>

<span class="s2">for </span><span class="s1">image_batch, labels_batch </span><span class="s2">in </span><span class="s1">train_ds:</span>
    <span class="s1">print(image_batch.shape)</span>
    <span class="s1">print(labels_batch.shape)</span>
    <span class="s2">break</span>

<span class="s0">## Configure the dataset for performance</span>
<span class="s1">AUTOTUNE = tf.data.AUTOTUNE</span>

<span class="s1">train_ds = train_ds.cache().shuffle(</span><span class="s4">1_000</span><span class="s1">).prefetch(buffer_size=AUTOTUNE)</span>
<span class="s1">val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)</span>

<span class="s0">## Standardize the data</span>
<span class="s1">normalization_layer = layers.Rescaling(</span><span class="s4">1</span><span class="s1">/</span><span class="s4">255.</span><span class="s1">)</span>

<span class="s1">normalized_ds = train_ds.map(</span><span class="s2">lambda </span><span class="s1">x, y: (normalization_layer(x), y))</span>
<span class="s1">image_batch, labels_batch = next(iter(normalized_ds))</span>
<span class="s1">first_image = image_batch[</span><span class="s4">0</span><span class="s1">]</span>
<span class="s0"># Notice the pixel values are now in '[0, 1]'.</span>
<span class="s1">print(np.min(first_image), np.max(first_image))</span>

<span class="s0">## A basic Keras model</span>
<span class="s0">### Create the model</span>
<span class="s1">num_classes = len(class_names)</span>

<span class="s1">model = Sequential([</span>
    <span class="s1">layers.Rescaling(</span><span class="s4">1</span><span class="s1">/</span><span class="s4">255.</span><span class="s1">, input_shape=(img_height, img_width, </span><span class="s4">3</span><span class="s1">)),</span>
    <span class="s1">layers.Conv2D(</span><span class="s4">16</span><span class="s1">, </span><span class="s4">3</span><span class="s1">, padding=</span><span class="s3">'same'</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">layers.MaxPooling2D(),</span>
    <span class="s1">layers.Conv2D(</span><span class="s4">32</span><span class="s1">, </span><span class="s4">3</span><span class="s1">, padding=</span><span class="s3">'same'</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">layers.MaxPooling2D(),</span>
    <span class="s1">layers.Conv2D(</span><span class="s4">64</span><span class="s1">, </span><span class="s4">3</span><span class="s1">, padding=</span><span class="s3">'same'</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">layers.MaxPooling2D(),</span>
    <span class="s1">layers.Flatten(),</span>
    <span class="s1">layers.Dense(</span><span class="s4">128</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">layers.Dense(num_classes)</span>
<span class="s1">])</span>

<span class="s0">### Compile the model</span>
<span class="s1">model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=</span><span class="s2">True</span><span class="s1">),</span>
              <span class="s1">optimizer=</span><span class="s3">'adam'</span><span class="s1">,</span>
              <span class="s1">metrics=[</span><span class="s3">'accuracy'</span><span class="s1">])</span>

<span class="s0">### Model summary</span>
<span class="s1">model.summary()</span>

<span class="s0">### Train the model</span>
<span class="s1">epochs=</span><span class="s4">10</span>
<span class="s1">history = model.fit(train_ds,</span>
                    <span class="s1">epochs=epochs,</span>
                    <span class="s1">validation_data=val_ds)</span>

<span class="s0">## Visualize training results</span>
<span class="s1">acc = history.history[</span><span class="s3">'accuracy'</span><span class="s1">]</span>
<span class="s1">val_acc = history.history[</span><span class="s3">'val_accuracy'</span><span class="s1">]</span>

<span class="s1">loss = history.history[</span><span class="s3">'loss'</span><span class="s1">]</span>
<span class="s1">val_loss = history.history[</span><span class="s3">'val_loss'</span><span class="s1">]</span>

<span class="s1">epochs_range = range(epochs)</span>

<span class="s1">plt.figure(figsize=(</span><span class="s4">8</span><span class="s1">, </span><span class="s4">8</span><span class="s1">))</span>
<span class="s1">plt.subplot(</span><span class="s4">1</span><span class="s1">, </span><span class="s4">2</span><span class="s1">, </span><span class="s4">1</span><span class="s1">)</span>
<span class="s1">plt.plot(epochs_range, acc, label=</span><span class="s3">'Training Accuracy'</span><span class="s1">)</span>
<span class="s1">plt.plot(epochs_range, val_acc, label=</span><span class="s3">'Validation Accuracy'</span><span class="s1">)</span>
<span class="s1">plt.legend(loc=</span><span class="s3">'lower right'</span><span class="s1">)</span>
<span class="s1">plt.title(</span><span class="s3">'Training &amp; Validation Accuracy'</span><span class="s1">)</span>

<span class="s1">plt.subplot(</span><span class="s4">1</span><span class="s1">, </span><span class="s4">2</span><span class="s1">, </span><span class="s4">2</span><span class="s1">)</span>
<span class="s1">plt.plot(epochs_range, loss, label=</span><span class="s3">'Training Loss'</span><span class="s1">)</span>
<span class="s1">plt.plot(epochs_range, val_loss, label=</span><span class="s3">'Validation Loss'</span><span class="s1">)</span>
<span class="s1">plt.legend(loc=</span><span class="s3">'upper right'</span><span class="s1">)</span>
<span class="s1">plt.title(</span><span class="s3">'Training &amp; Validation Loss'</span><span class="s1">)</span>
<span class="s1">plt.show()</span>

<span class="s0">## Overfitting</span>

<span class="s0">## Data augmentation</span>
<span class="s1">data_augmentation = keras.Sequential([</span>
    <span class="s1">layers.RandomFlip(</span><span class="s3">&quot;horizontal&quot;</span><span class="s1">, input_shape=(img_height, img_width, </span><span class="s4">3</span><span class="s1">)),</span>
    <span class="s1">layers.RandomRotation(</span><span class="s4">0.1</span><span class="s1">),</span>
    <span class="s1">layers.RandomZoom(</span><span class="s4">0.1</span><span class="s1">)</span>
<span class="s1">])</span>

<span class="s1">plt.figure(figsize=(</span><span class="s4">10</span><span class="s1">, </span><span class="s4">10</span><span class="s1">))</span>
<span class="s2">for </span><span class="s1">images, _ </span><span class="s2">in </span><span class="s1">train_ds.take(</span><span class="s4">1</span><span class="s1">):</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">9</span><span class="s1">):</span>
        <span class="s1">augmented_images = data_augmentation(images)</span>
        <span class="s1">ax = plt.subplot(</span><span class="s4">3</span><span class="s1">, </span><span class="s4">3</span><span class="s1">, i + </span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">plt.imshow(augmented_images[</span><span class="s4">0</span><span class="s1">].numpy().astype(</span><span class="s3">&quot;uint8&quot;</span><span class="s1">))</span>
        <span class="s1">plt.axis(</span><span class="s3">&quot;off&quot;</span><span class="s1">)</span>

<span class="s0">## Dropout</span>
<span class="s1">model = Sequential([</span>
    <span class="s1">data_augmentation,</span>
    <span class="s1">layers.Rescaling(</span><span class="s4">1</span><span class="s1">/</span><span class="s4">255.</span><span class="s1">),</span>
    <span class="s1">layers.Conv2D(</span><span class="s4">16</span><span class="s1">, </span><span class="s4">3</span><span class="s1">, padding=</span><span class="s3">'same'</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">layers.MaxPooling2D(),</span>
    <span class="s1">layers.Conv2D(</span><span class="s4">32</span><span class="s1">, </span><span class="s4">3</span><span class="s1">, padding=</span><span class="s3">'same'</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">layers.MaxPooling2D(),</span>
    <span class="s1">layers.Conv2D(</span><span class="s4">64</span><span class="s1">, </span><span class="s4">3</span><span class="s1">, padding=</span><span class="s3">'same'</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">layers.MaxPooling2D(),</span>
    <span class="s1">layers.Dropout(</span><span class="s4">0.2</span><span class="s1">),</span>
    <span class="s1">layers.Flatten(),</span>
    <span class="s1">layers.Dense(</span><span class="s4">128</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">layers.Dense(num_classes, name=</span><span class="s3">&quot;outputs&quot;</span><span class="s1">)</span>
<span class="s1">])</span>

<span class="s0">## Compile and train the model</span>
<span class="s1">model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=</span><span class="s2">True</span><span class="s1">),</span>
              <span class="s1">optimizer=</span><span class="s3">'adam'</span><span class="s1">,</span>
              <span class="s1">metrics=[</span><span class="s3">'accuracy'</span><span class="s1">])</span>

<span class="s1">model.summary()</span>

<span class="s1">epochs = </span><span class="s4">15</span>

<span class="s1">history = model.fit(train_ds,</span>
                    <span class="s1">epochs=epochs,</span>
                    <span class="s1">validation_data=val_ds)</span>

<span class="s0">## Visualize training results</span>
<span class="s1">acc = history.history[</span><span class="s3">'accuracy'</span><span class="s1">]</span>
<span class="s1">val_acc = history.history[</span><span class="s3">'val_accuracy'</span><span class="s1">]</span>

<span class="s1">loss = history.history[</span><span class="s3">'loss'</span><span class="s1">]</span>
<span class="s1">val_loss = history.history[</span><span class="s3">'val_loss'</span><span class="s1">]</span>

<span class="s1">epochs_range = range(epochs)</span>

<span class="s1">plt.figure(figsize=(</span><span class="s4">8</span><span class="s1">, </span><span class="s4">8</span><span class="s1">))</span>
<span class="s1">plt.subplot(</span><span class="s4">1</span><span class="s1">, </span><span class="s4">2</span><span class="s1">, </span><span class="s4">1</span><span class="s1">)</span>
<span class="s1">plt.plot(epochs_range, acc, label=</span><span class="s3">'Training Accuracy'</span><span class="s1">)</span>
<span class="s1">plt.plot(epochs_range, val_acc, label=</span><span class="s3">'Validation Accuracy'</span><span class="s1">)</span>
<span class="s1">plt.legend(loc=</span><span class="s3">'lower right'</span><span class="s1">)</span>
<span class="s1">plt.title(</span><span class="s3">'Training &amp; Validation Accuracy'</span><span class="s1">)</span>

<span class="s1">plt.subplot(</span><span class="s4">1</span><span class="s1">, </span><span class="s4">2</span><span class="s1">, </span><span class="s4">2</span><span class="s1">)</span>
<span class="s1">plt.plot(epochs_range, loss, label=</span><span class="s3">'Training Loss'</span><span class="s1">)</span>
<span class="s1">plt.plot(epochs_range, val_loss, label=</span><span class="s3">'Validation Loss'</span><span class="s1">)</span>
<span class="s1">plt.legend(loc=</span><span class="s3">'upper right'</span><span class="s1">)</span>
<span class="s1">plt.title(</span><span class="s3">'Training &amp; Validation Loss'</span><span class="s1">)</span>
<span class="s1">plt.show()</span>

<span class="s0">## Predict on new data</span>
<span class="s1">sunflower_url = </span><span class="s3">&quot;https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg&quot;</span>
<span class="s1">sunflower_path = tf.keras.utils.get_file(</span><span class="s3">'Red_sunflower'</span><span class="s1">, origin=sunflower_url)</span>

<span class="s1">img = tf.keras.utils.load_img(sunflower_path, target_size=(img_height, img_width))</span>
<span class="s1">img_array = tf.keras.utils.img_to_array(img)</span>
<span class="s1">img_array = tf.expand_dims(img_array, </span><span class="s4">0</span><span class="s1">) </span><span class="s0"># Create a batch</span>

<span class="s1">predictions = model.predict(img_array)</span>
<span class="s1">score = tf.nn.softmax(predictions[</span><span class="s4">0</span><span class="s1">])</span>

<span class="s1">print(</span><span class="s3">&quot;This image most likely belongs to {} w/ a {:.2f} percent confidence.&quot;</span>
      <span class="s1">.format(class_names[np.argmax(score)], </span><span class="s4">100 </span><span class="s1">* np.max(score)))</span>

<span class="s0">## Use TensorFlow Lite</span>
<span class="s0">### Convert the Keras Sequential model to a TensorFlow Lite model</span>

<span class="s0"># Convert the model.</span>
<span class="s1">converter = tf.lite.TFLiteConverter.from_keras_model(model)</span>
<span class="s1">tflite_model = converter.convert()</span>

<span class="s0"># Save the model.</span>
<span class="s2">with </span><span class="s1">open(</span><span class="s3">'model.tf.lite'</span><span class="s1">, </span><span class="s3">'wb'</span><span class="s1">) </span><span class="s2">as </span><span class="s1">f:</span>
    <span class="s1">f.write(tflite_model)</span>

<span class="s0">### Run the TensorFlow Lite model</span>
<span class="s1">TF_MODEL_FILE_PATH = </span><span class="s3">'model.tflite' </span><span class="s0"># The default path to the saved TensorFlow Lite model</span>
<span class="s1">interpreter = tf.lite.Interpreter(model_path=TF_MODEL_FILE_PATH)</span>

<span class="s1">interpreter.get_signature_list()</span>

<span class="s1">classify_lite = interpreter.get_signature_runner(</span><span class="s3">'serving_default'</span><span class="s1">)</span>
<span class="s1">classify_lite</span>

<span class="s1">predictions_lite = classify_lite(sequential_1_input=img_array)[</span><span class="s3">'outputs'</span><span class="s1">]</span>
<span class="s1">score_lite = tf.nn.softmax(predictions_lite)</span>

<span class="s1">print(</span><span class="s3">&quot;This image most likely belongs to {} w/ a {:.2f} percent confidence.&quot;</span>
      <span class="s1">.format(class_names[np.argmax(score_lite)], </span><span class="s4">100 </span><span class="s1">* np.max(score_lite)))</span>

<span class="s1">print(np.max(np.abs(predictions - predictions_lite)))</span></pre>
</body>
</html>