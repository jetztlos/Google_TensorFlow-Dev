<html>
<head>
<title>Num_TimeSeriesForecasting.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #8c8c8c; font-style: italic;}
.s1 { color: #080808;}
.s2 { color: #0033b3;}
.s3 { color: #067d17;}
.s4 { color: #1750eb;}
.s5 { color: #0037a6;}
.ls0 { height: 1px; border-width: 0; color: #dfe1e5; background-color:#dfe1e5}
</style>
</head>
<body bgcolor="#ffffff">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#c0c0c0" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
Num_TimeSeriesForecasting.py</font>
</center></td></tr></table>
<pre><span class="s0"># From: https://www.tensorflow.org/tutorials/structured_data/time_series</span>
<span class="s0">## Setup</span>
<span class="s2">import </span><span class="s1">os</span>
<span class="s2">import </span><span class="s1">datetime</span>

<span class="s0"># import IPython</span>
<span class="s0"># import IPython.display</span>
<span class="s2">import </span><span class="s1">matplotlib </span><span class="s2">as </span><span class="s1">mpl</span>
<span class="s2">import </span><span class="s1">matplotlib.pyplot </span><span class="s2">as </span><span class="s1">plt</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s0"># import seaborn as sns</span>
<span class="s2">import </span><span class="s1">tensorflow </span><span class="s2">as </span><span class="s1">tf</span>

<span class="s1">mpl.rcParams[</span><span class="s3">'figure.figsize'</span><span class="s1">] = (</span><span class="s4">8</span><span class="s1">, </span><span class="s4">6</span><span class="s1">)</span>
<span class="s1">mpl.rcParams[</span><span class="s3">'axes.grid'</span><span class="s1">] = </span><span class="s2">False</span>

<span class="s0">## The weather dataset</span>
<span class="s1">zip_path = tf.keras.utils.get_file(</span>
    <span class="s1">origin=</span><span class="s3">'https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip'</span><span class="s1">,</span>
    <span class="s1">fname=</span><span class="s3">'jena_climate_2009_2016.csv.zip'</span><span class="s1">,</span>
    <span class="s1">extract=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s1">csv_path, _ = os.path.splitext(zip_path)</span>

<span class="s1">df = pd.read_csv(csv_path)</span>
<span class="s0"># Slice [start:stop:step], starting from index 5 take every 6th record.</span>
<span class="s1">df = df[</span><span class="s4">5</span><span class="s1">::</span><span class="s4">6</span><span class="s1">]</span>

<span class="s1">date_time = pd.to_datetime(df.pop(</span><span class="s3">'Date Time'</span><span class="s1">), format=</span><span class="s3">'%d.%m.%Y %H:%M:%S'</span><span class="s1">)</span>

<span class="s1">df.head()</span>

<span class="s1">plot_cols = [</span><span class="s3">'T (degC)'</span><span class="s1">, </span><span class="s3">'p (mbar)'</span><span class="s1">, </span><span class="s3">'rho (g/m**3)'</span><span class="s1">]</span>
<span class="s1">plot_features = df[plot_cols]</span>
<span class="s1">plot_features.index = date_time</span>
<span class="s1">_ = plot_features.plot(subplots=</span><span class="s2">True</span><span class="s1">)</span>

<span class="s1">plot_features = df[plot_cols][:</span><span class="s4">480</span><span class="s1">]</span>
<span class="s1">plot_features.index = date_time[:</span><span class="s4">480</span><span class="s1">]</span>
<span class="s1">_ = plot_features.plot(subplots=</span><span class="s2">True</span><span class="s1">)</span>

<span class="s0">### Inspect and cleanup</span>
<span class="s1">df.describe().transpose()</span>

<span class="s0"># Wind velocity</span>
<span class="s1">wv = df[</span><span class="s3">'wv (m/s)'</span><span class="s1">]</span>
<span class="s1">bad_wv = wv == -</span><span class="s4">9999.0</span>
<span class="s1">wv[bad_wv] = </span><span class="s4">0.0</span>

<span class="s1">max_wv = df[</span><span class="s3">'max. wv (m/s)'</span><span class="s1">]</span>
<span class="s1">bad_max_wv = max_wv == -</span><span class="s4">9999.0</span>
<span class="s1">max_wv[bad_max_wv] = </span><span class="s4">0.0</span>

<span class="s0"># The above inplace edits are reflected in the DataFrame.</span>
<span class="s1">df[</span><span class="s3">'wv (m/s)'</span><span class="s1">].min()</span>

<span class="s0">### Feature engineering</span>
<span class="s0"># Wind</span>
<span class="s1">plt.hist2d(df[</span><span class="s3">'wd (deg)'</span><span class="s1">], df[</span><span class="s3">'wv (m/s)'</span><span class="s1">], bins=(</span><span class="s4">50</span><span class="s1">, </span><span class="s4">50</span><span class="s1">), vmax=</span><span class="s4">400</span><span class="s1">)</span>
<span class="s1">plt.colorbar()</span>
<span class="s1">plt.xlabel(</span><span class="s3">'Wind Direction [deg]'</span><span class="s1">)</span>
<span class="s1">plt.ylabel(</span><span class="s3">'Wind Velocity [m/s]'</span><span class="s1">)</span>

<span class="s1">wv = df.pop(</span><span class="s3">'wv (m/s)'</span><span class="s1">)</span>
<span class="s1">max_wv = df.pop(</span><span class="s3">'max. wv (m/s)'</span><span class="s1">)</span>

<span class="s0"># Convert to radians.</span>
<span class="s1">wd_rad = df.pop(</span><span class="s3">'wd (deg)'</span><span class="s1">)*np.pi / </span><span class="s4">180</span>

<span class="s0"># Calculate the wind x and y components.</span>
<span class="s1">df[</span><span class="s3">'Wx'</span><span class="s1">] = wv * np.cos(wd_rad)</span>
<span class="s1">df[</span><span class="s3">'Wy'</span><span class="s1">] = wv * np.sin(wd_rad)</span>

<span class="s0"># Calculate the max wind x and y components.</span>
<span class="s1">df[</span><span class="s3">'max Wx'</span><span class="s1">] = max_wv * np.cos(wd_rad)</span>
<span class="s1">df[</span><span class="s3">'max Wy'</span><span class="s1">] = max_wv * np.sin(wd_rad)</span>

<span class="s1">plt.hist2d(df[</span><span class="s3">'Wx'</span><span class="s1">], df[</span><span class="s3">'Wy'</span><span class="s1">], bins=(</span><span class="s4">50</span><span class="s1">, </span><span class="s4">50</span><span class="s1">), vmax=</span><span class="s4">400</span><span class="s1">)</span>
<span class="s1">plt.colorbar()</span>
<span class="s1">plt.xlabel(</span><span class="s3">'Wind X [m/s]'</span><span class="s1">)</span>
<span class="s1">plt.ylabel(</span><span class="s3">'Wind Y [m/s]'</span><span class="s1">)</span>
<span class="s1">ax = plt.gca()</span>
<span class="s1">ax.axis(</span><span class="s3">'tight'</span><span class="s1">)</span>

<span class="s0"># Time</span>
<span class="s1">timestamp_s = date_time.map(pd.Timestamp.timestamp)</span>

<span class="s1">day = </span><span class="s4">24 </span><span class="s1">* </span><span class="s4">60 </span><span class="s1">* </span><span class="s4">60</span>
<span class="s1">year = (</span><span class="s4">365.2425</span><span class="s1">) * day</span>

<span class="s1">df[</span><span class="s3">'Day sin'</span><span class="s1">] = np.sin(timestamp_s * (</span><span class="s4">2 </span><span class="s1">* np.pi / day))</span>
<span class="s1">df[</span><span class="s3">'Day cos'</span><span class="s1">] = np.cos(timestamp_s * (</span><span class="s4">2 </span><span class="s1">* np.pi / day))</span>
<span class="s1">df[</span><span class="s3">'Year sin'</span><span class="s1">] = np.sin(timestamp_s * (</span><span class="s4">2 </span><span class="s1">* np.pi / year))</span>
<span class="s1">df[</span><span class="s3">'Year cos'</span><span class="s1">] = np.cos(timestamp_s * (</span><span class="s4">2 </span><span class="s1">* np.pi / year))</span>

<span class="s1">plt.plot(np.array(df[</span><span class="s3">'Day sin'</span><span class="s1">])[:</span><span class="s4">25</span><span class="s1">])</span>
<span class="s1">plt.plot(np.array(df[</span><span class="s3">'Day cos'</span><span class="s1">])[:</span><span class="s4">25</span><span class="s1">])</span>
<span class="s1">plt.xlabel(</span><span class="s3">'Time [h]'</span><span class="s1">)</span>
<span class="s1">plt.title(</span><span class="s3">'Time of day signal'</span><span class="s1">)</span>

<span class="s1">fft = tf.signal.rfft(df[</span><span class="s3">'T (degC)'</span><span class="s1">]) </span><span class="s0"># Fast Fourier Transform</span>
<span class="s1">f_per_dataset = np.arange(</span><span class="s4">0</span><span class="s1">, len(fft))</span>

<span class="s1">n_samples_h = len(df[</span><span class="s3">'T (degC)'</span><span class="s1">])</span>
<span class="s1">hours_per_year = </span><span class="s4">24 </span><span class="s1">* </span><span class="s4">365.2524</span>
<span class="s1">years_per_dataset = n_samples_h / hours_per_year</span>

<span class="s1">f_per_year = f_per_dataset / years_per_dataset</span>
<span class="s1">plt.step(f_per_year, np.abs(fft))</span>
<span class="s1">plt.xscale(</span><span class="s3">'log'</span><span class="s1">)</span>
<span class="s1">plt.ylim(</span><span class="s4">0</span><span class="s1">, </span><span class="s4">400_000</span><span class="s1">)</span>
<span class="s1">plt.xlim([</span><span class="s4">0.1</span><span class="s1">, max(plt.xlim())])</span>
<span class="s1">plt.xticks([</span><span class="s4">1</span><span class="s1">, </span><span class="s4">365.2524</span><span class="s1">], labels=[</span><span class="s3">'1/Year'</span><span class="s1">, </span><span class="s3">'1/day'</span><span class="s1">])</span>
<span class="s1">_ = plt.xlabel(</span><span class="s3">'Frequency (log scale)'</span><span class="s1">)</span>

<span class="s0">### Split the data</span>
<span class="s1">column_indices = {name: i </span><span class="s2">for </span><span class="s1">i, name </span><span class="s2">in </span><span class="s1">enumerate(df.columns)}</span>

<span class="s1">n = len(df)</span>
<span class="s1">train_df = df[</span><span class="s4">0          </span><span class="s1">: int(n*</span><span class="s4">0.7</span><span class="s1">)]</span>
<span class="s1">val_df   = df[int(n*</span><span class="s4">0.7</span><span class="s1">) : int(n*</span><span class="s4">0.9</span><span class="s1">)]</span>
<span class="s1">test_df  = df[int(n*</span><span class="s4">0.9</span><span class="s1">) : ]</span>

<span class="s1">num_features = df.shape[</span><span class="s4">1</span><span class="s1">]</span>

<span class="s0">### Normalize the data</span>
<span class="s1">train_mean = train_df.mean()</span>
<span class="s1">train_std = train_df.std()</span>

<span class="s1">train_df = (train_df - train_mean) / train_std</span>
<span class="s1">val_df = (val_df - train_mean) / train_std</span>
<span class="s1">test_df = (test_df - train_mean) / train_std</span>

<span class="s1">df_std = (df - train_mean) / train_std</span>
<span class="s1">df_std = df_std.melt(var_name=</span><span class="s3">'Column'</span><span class="s1">, value_name=</span><span class="s3">'Normalized'</span><span class="s1">)</span>
<span class="s1">plt.figure(figsize=(</span><span class="s4">12</span><span class="s1">, </span><span class="s4">6</span><span class="s1">))</span>
<span class="s0"># ax = sns.violinplot(x='Column', y='Normalized', data=df_std)</span>
<span class="s0"># _ = ax.set_xticklabels(df.keys(), rotation=90)</span>

<span class="s0">## Data windowing</span>
<span class="s0">### 1. Indexes and offsets</span>
<span class="s2">class </span><span class="s1">WindowGenerator():</span>
    <span class="s2">def </span><span class="s1">__init__(self, input_width, label_width, shift,</span>
                 <span class="s1">train_df=train_df, val_df=val_df, test_df=test_df,</span>
                 <span class="s1">label_columns=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0"># Store the raw data.</span>
        <span class="s1">self.train_df = train_df</span>
        <span class="s1">self.val_df = val_df</span>
        <span class="s1">self.test_df = test_df</span>

        <span class="s0"># Work out the label column indices.</span>
        <span class="s1">self.label_columns = label_columns</span>
        <span class="s2">if </span><span class="s1">label_columns </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">self.label_columns_indices = {name: i </span><span class="s2">for </span><span class="s1">i, name </span><span class="s2">in </span><span class="s1">enumerate(label_columns)}</span>
        <span class="s1">self.column_indices = {name: i </span><span class="s2">for </span><span class="s1">i, name </span><span class="s2">in </span><span class="s1">enumerate(train_df.columns)}</span>

        <span class="s0"># Work out the window parameters.</span>
        <span class="s1">self.input_width = input_width</span>
        <span class="s1">self.label_width = label_width</span>
        <span class="s1">self.shift = shift</span>

        <span class="s1">self.total_window_size = input_width + shift</span>

        <span class="s1">self.input_slice = slice(</span><span class="s4">0</span><span class="s1">, input_width)</span>
        <span class="s1">self.input_indices = np.arange(self.total_window_size)[self.input_slice]</span>

        <span class="s1">self.label_start = self.total_window_size - self.label_width</span>
        <span class="s1">self.labels_slice = slice(self.label_start, </span><span class="s2">None</span><span class="s1">)</span>
        <span class="s1">self.label_indices = np.arange(self.total_window_size)[self.labels_slice]</span>

    <span class="s2">def </span><span class="s1">__repr__(self):</span>
        <span class="s2">return </span><span class="s3">'</span><span class="s5">\n</span><span class="s3">'</span><span class="s1">.join([</span>
            <span class="s3">f'Total window size: </span><span class="s5">{</span><span class="s1">self.total_window_size</span><span class="s5">}</span><span class="s3">'</span><span class="s1">,</span>
            <span class="s3">f'Input indices: </span><span class="s5">{</span><span class="s1">self.input_indices</span><span class="s5">}</span><span class="s3">'</span><span class="s1">,</span>
            <span class="s3">f'Label indices: </span><span class="s5">{</span><span class="s1">self.label_indices</span><span class="s5">}</span><span class="s3">'</span><span class="s1">,</span>
            <span class="s3">f'Label column name(s): </span><span class="s5">{</span><span class="s1">self.label_columns</span><span class="s5">}</span><span class="s3">'</span>
        <span class="s1">])</span>

<span class="s1">w1 = WindowGenerator(input_width=</span><span class="s4">24</span><span class="s1">, label_width=</span><span class="s4">1</span><span class="s1">, shift=</span><span class="s4">24</span><span class="s1">, label_columns=[</span><span class="s3">'T (degC)'</span><span class="s1">])</span>
<span class="s1">w1</span>

<span class="s1">w2 = WindowGenerator(input_width=</span><span class="s4">6</span><span class="s1">, label_width=</span><span class="s4">1</span><span class="s1">, shift=</span><span class="s4">1</span><span class="s1">, label_columns=[</span><span class="s3">'T (degC)'</span><span class="s1">])</span>
<span class="s1">w2</span>

<span class="s0">### 2. Split</span>
<span class="s2">def </span><span class="s1">split_window(self, features):</span>
    <span class="s1">inputs = features[:, self.input_slice, :]</span>
    <span class="s1">labels = features[:, self.labels_slice, :]</span>
    <span class="s2">if </span><span class="s1">self.label_columns </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s1">labels = tf.stack(</span>
            <span class="s1">[labels[:, :, self.column_indices[name]] </span><span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">self.label_columns],</span>
            <span class="s1">axis=-</span><span class="s4">1</span>
        <span class="s1">)</span>

    <span class="s0"># Slicing doesn't preserve static shape info., so set the</span>
    <span class="s0"># shapes manually. This way the `tf.data.Datasets` are easier to inspect.</span>
    <span class="s1">inputs.set_shape([</span><span class="s2">None</span><span class="s1">, self.input_width, </span><span class="s2">None</span><span class="s1">])</span>
    <span class="s1">labels.set_shape([</span><span class="s2">None</span><span class="s1">, self.label_width, </span><span class="s2">None</span><span class="s1">])</span>

    <span class="s2">return </span><span class="s1">inputs, labels</span>

<span class="s1">WindowGenerator.split_window = split_window</span>

<span class="s0"># Stack 3 slices, the length of the total window.</span>
<span class="s1">example_window = tf.stack([np.array(train_df[    : w2.total_window_size]),</span>
                           <span class="s1">np.array(train_df[</span><span class="s4">100 </span><span class="s1">: </span><span class="s4">100 </span><span class="s1">+ w2.total_window_size]),</span>
                           <span class="s1">np.array(train_df[</span><span class="s4">200 </span><span class="s1">: </span><span class="s4">200 </span><span class="s1">+ w2.total_window_size])])</span>

<span class="s1">example_inputs, example_labels = w2.split_window(example_window)</span>

<span class="s1">print(</span><span class="s3">'All shapes are: (batch, time, features)'</span><span class="s1">)</span>
<span class="s1">print(</span><span class="s3">f'Window shape: </span><span class="s5">{</span><span class="s1">example_window.shape</span><span class="s5">}</span><span class="s3">'</span><span class="s1">)</span>
<span class="s1">print(</span><span class="s3">f'Inputs shape: </span><span class="s5">{</span><span class="s1">example_inputs.shape</span><span class="s5">}</span><span class="s3">'</span><span class="s1">)</span>
<span class="s1">print(</span><span class="s3">f'Labels shape: </span><span class="s5">{</span><span class="s1">example_labels.shape</span><span class="s5">}</span><span class="s3">'</span><span class="s1">)</span>

<span class="s0">### 3. Plot</span>
<span class="s1">w2.example = example_inputs, example_labels</span>

<span class="s2">def </span><span class="s1">plot(self, model=</span><span class="s2">None</span><span class="s1">, plot_col=</span><span class="s3">'T (degC)'</span><span class="s1">, max_subplots=</span><span class="s4">3</span><span class="s1">):</span>
    <span class="s1">inputs, labels = self.example</span>
    <span class="s1">plt.figure(figsize=(</span><span class="s4">12</span><span class="s1">, </span><span class="s4">8</span><span class="s1">))</span>
    <span class="s1">plot_col_index = self.column_indices[plot_col]</span>
    <span class="s1">max_n = min(max_subplots, len(inputs))</span>
    <span class="s2">for </span><span class="s1">n </span><span class="s2">in </span><span class="s1">range(max_n):</span>
        <span class="s1">plt.subplot(max_n, </span><span class="s4">1</span><span class="s1">, n+</span><span class="s4">1</span><span class="s1">)</span>
        <span class="s1">plt.ylabel(</span><span class="s3">f' </span><span class="s5">{</span><span class="s1">plot_col</span><span class="s5">} </span><span class="s3">[normed]'</span><span class="s1">)</span>
        <span class="s1">plt.plot(self.input_indices, inputs[n, :, plot_col_index],</span>
                 <span class="s1">label=</span><span class="s3">'Inputs'</span><span class="s1">, marker=</span><span class="s3">'.'</span><span class="s1">, zorder=-</span><span class="s4">10</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">self.label_columns:</span>
            <span class="s1">label_col_index = self.label_columns_indices.get(plot_col, </span><span class="s2">None</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">label_col_index = plot_col_index</span>

        <span class="s2">if </span><span class="s1">label_col_index </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s2">continue</span>

        <span class="s1">plt.scatter(self.label_indices, labels[n, :, label_col_index],</span>
                    <span class="s1">edgecolors=</span><span class="s3">'k'</span><span class="s1">, label=</span><span class="s3">'Labels'</span><span class="s1">, c=</span><span class="s3">'#2ca02c'</span><span class="s1">, s=</span><span class="s4">64</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">model </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">predictions = model(inputs)</span>
            <span class="s1">plt.scatter(self.label_indices, predictions[n, :, label_col_index],</span>
                        <span class="s1">marker=</span><span class="s3">'X'</span><span class="s1">, edgecolors=</span><span class="s3">'k'</span><span class="s1">, label=</span><span class="s3">'Predictions'</span><span class="s1">,</span>
                        <span class="s1">c=</span><span class="s3">'#ff7f0e'</span><span class="s1">, s=</span><span class="s4">64</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">n == </span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">plt.legend()</span>

    <span class="s1">plt.xlabel(</span><span class="s3">'Time [h]'</span><span class="s1">)</span>

<span class="s1">WindowGenerator.plot = plot</span>

<span class="s1">w2.plot()</span>

<span class="s1">w2.plot(plot_col=</span><span class="s3">'p (mbar)'</span><span class="s1">)</span>

<span class="s0">### 4. Create tf.data.Datasets</span>
<span class="s2">def </span><span class="s1">make_dataset(self, data):</span>
    <span class="s1">data = np.array(data, dtype=np.float32)</span>
    <span class="s1">ds = tf.keras.utils.timeseries_dataset_from_array(</span>
        <span class="s1">data=data,</span>
        <span class="s1">targets=</span><span class="s2">None</span><span class="s1">,</span>
        <span class="s1">sequence_length=self.total_window_size,</span>
        <span class="s1">sequence_stride=</span><span class="s4">1</span><span class="s1">,</span>
        <span class="s1">shuffle=</span><span class="s2">True</span><span class="s1">,</span>
        <span class="s1">batch_size=</span><span class="s4">32</span>
    <span class="s1">)</span>

    <span class="s1">ds = ds.map(self.split_window)</span>

    <span class="s2">return </span><span class="s1">ds</span>

<span class="s1">WindowGenerator.make_dataset = make_dataset</span>

<span class="s1">@property</span>
<span class="s2">def </span><span class="s1">train(self):</span>
    <span class="s2">return </span><span class="s1">self.make_dataset(self.train_df)</span>

<span class="s1">@property</span>
<span class="s2">def </span><span class="s1">val(self):</span>
    <span class="s2">return </span><span class="s1">self.make_dataset(self.val_df)</span>

<span class="s1">@property</span>
<span class="s2">def </span><span class="s1">test(self):</span>
    <span class="s2">return </span><span class="s1">self.make_dataset(self.test_df)</span>

<span class="s1">@property</span>
<span class="s2">def </span><span class="s1">example(self):</span>
    <span class="s0">&quot;&quot;&quot;Get and cache an ex. batch of `inputs, labels` for plotting.&quot;&quot;&quot;</span>
    <span class="s1">result = getattr(self, </span><span class="s3">'_example'</span><span class="s1">, </span><span class="s2">None</span><span class="s1">)</span>
    <span class="s2">if </span><span class="s1">result </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s0"># No ex. batch was found, so get one from the `.train` dataset</span>
        <span class="s1">result = next(iter(self.train))</span>
        <span class="s0"># And cache it for next time</span>
        <span class="s1">self._example = result</span>
    <span class="s2">return </span><span class="s1">result</span>

<span class="s1">WindowGenerator.train = train</span>
<span class="s1">WindowGenerator.val = val</span>
<span class="s1">WindowGenerator.test = test</span>
<span class="s1">WindowGenerator.example = example</span>

<span class="s0"># Each element is an (inputs, label) pair.</span>
<span class="s1">w2.train.element_spec</span>

<span class="s2">for </span><span class="s1">example_inputs, example_labels </span><span class="s2">in </span><span class="s1">w2.train.take(</span><span class="s4">1</span><span class="s1">):</span>
    <span class="s1">print(</span><span class="s3">f'Inputs shape (batch, time, features): </span><span class="s5">{</span><span class="s1">example_inputs.shape</span><span class="s5">}</span><span class="s3">'</span><span class="s1">)</span>
    <span class="s1">print(</span><span class="s3">f'Labels shape (batch, time, features): </span><span class="s5">{</span><span class="s1">example_labels.shape</span><span class="s5">}</span><span class="s3">'</span><span class="s1">)</span>

<span class="s0">## Single step models</span>
<span class="s1">single_step_window = WindowGenerator(</span>
    <span class="s1">input_width=</span><span class="s4">1</span><span class="s1">, label_width=</span><span class="s4">1</span><span class="s1">, shift=</span><span class="s4">1</span><span class="s1">,</span>
    <span class="s1">label_columns=[</span><span class="s3">'T (degC)'</span><span class="s1">]</span>
<span class="s1">)</span>
<span class="s1">single_step_window = WindowGenerator(</span>
    <span class="s1">input_width=</span><span class="s4">1</span><span class="s1">, label_width=</span><span class="s4">1</span><span class="s1">, shift=</span><span class="s4">1</span><span class="s1">,</span>
    <span class="s1">label_columns=[</span><span class="s3">'T (degC)'</span><span class="s1">]</span>
<span class="s1">)</span>
<span class="s1">single_step_window</span>

<span class="s2">for </span><span class="s1">example_inputs, example_labels </span><span class="s2">in </span><span class="s1">single_step_window.train.take(</span><span class="s4">1</span><span class="s1">):</span>
    <span class="s1">print(</span><span class="s3">f'Inputs shape (batch, time, features): </span><span class="s5">{</span><span class="s1">example_inputs.shape</span><span class="s5">}</span><span class="s3">'</span><span class="s1">)</span>
    <span class="s1">print(</span><span class="s3">f'Labels shape (batch, time, features): </span><span class="s5">{</span><span class="s1">example_labels.shape</span><span class="s5">}</span><span class="s3">'</span><span class="s1">)</span>

<span class="s0">### Baseline</span>
<span class="s2">class </span><span class="s1">Baseline(tf.keras.Model):</span>
    <span class="s2">def </span><span class="s1">__init__(self, label_index=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">super().__init__()</span>
        <span class="s1">self.label_index = label_index</span>

    <span class="s2">def </span><span class="s1">call(self, inputs):</span>
        <span class="s2">if </span><span class="s1">self.label_index </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">inputs</span>
        <span class="s1">result = inputs[:, :, self.label_index]</span>
        <span class="s2">return </span><span class="s1">result[:, :, tf.newaxis]</span>

<span class="s1">baseline = Baseline(label_index=column_indices[</span><span class="s3">'T (degC)'</span><span class="s1">])</span>

<span class="s1">baseline.compile(loss=tf.keras.losses.MeanSquaredError(),</span>
                 <span class="s1">metrics=[tf.keras.metrics.MeanAbsoluteError()])</span>

<span class="s1">val_performance = {}</span>
<span class="s1">performance = {}</span>
<span class="s1">val_performance[</span><span class="s3">'Baseline'</span><span class="s1">] = baseline.evaluate(single_step_window.val)</span>
<span class="s1">performance[</span><span class="s3">'Baseline'</span><span class="s1">] = baseline.evaluate(single_step_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>

<span class="s1">wide_window = WindowGenerator(</span>
    <span class="s1">input_width=</span><span class="s4">24</span><span class="s1">, label_width=</span><span class="s4">24</span><span class="s1">, shift=</span><span class="s4">1</span><span class="s1">,</span>
    <span class="s1">label_columns=[</span><span class="s3">'T (degC)'</span><span class="s1">]</span>
<span class="s1">)</span>
<span class="s1">wide_window</span>

<span class="s1">print(</span><span class="s3">'Input shape:'</span><span class="s1">, wide_window.example[</span><span class="s4">0</span><span class="s1">].shape)</span>
<span class="s1">print(</span><span class="s3">'Output shape:'</span><span class="s1">, baseline(wide_window.example[</span><span class="s4">0</span><span class="s1">]).shape)</span>

<span class="s1">wide_window.plot(baseline)</span>

<span class="s0">### Linear model</span>
<span class="s1">linear = tf.keras.Sequential([</span>
    <span class="s1">tf.keras.layers.Dense(units=</span><span class="s4">1</span><span class="s1">)</span>
<span class="s1">])</span>

<span class="s1">print(</span><span class="s3">'Input shape:'</span><span class="s1">, single_step_window.example[</span><span class="s4">0</span><span class="s1">].shape)</span>
<span class="s1">print(</span><span class="s3">'Output shape:'</span><span class="s1">, linear(single_step_window.example[</span><span class="s4">0</span><span class="s1">]).shape)</span>

<span class="s1">MAX_EPOCHS = </span><span class="s4">20</span>

<span class="s2">def </span><span class="s1">compile_and_fit(model, window, patience=</span><span class="s4">2</span><span class="s1">):</span>
    <span class="s1">early_stopping = tf.keras.callbacks.EarlyStopping(monitor=</span><span class="s3">'val_loss'</span><span class="s1">,</span>
                                                      <span class="s1">patience=patience,</span>
                                                      <span class="s1">mode=</span><span class="s3">'min'</span><span class="s1">)</span>

    <span class="s1">model.compile(loss=tf.keras.losses.MeanSquaredError(),</span>
                  <span class="s1">optimizer=tf.keras.optimizers.Adam(),</span>
                  <span class="s1">metrics=[tf.keras.metrics.MeanAbsoluteError()])</span>

    <span class="s1">history = model.fit(window.train,</span>
                        <span class="s1">epochs=MAX_EPOCHS,</span>
                        <span class="s1">validation_data=window.val,</span>
                        <span class="s1">callbacks=[early_stopping])</span>
    <span class="s2">return </span><span class="s1">history</span>

<span class="s1">history = compile_and_fit(linear, single_step_window)</span>

<span class="s1">val_performance[</span><span class="s3">'Linear'</span><span class="s1">] = linear.evaluate(single_step_window.val)</span>
<span class="s1">performance[</span><span class="s3">'Linear'</span><span class="s1">] = linear.evaluate(single_step_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>

<span class="s1">print(</span><span class="s3">'Input shape:'</span><span class="s1">, wide_window.example[</span><span class="s4">0</span><span class="s1">].shape)</span>
<span class="s1">print(</span><span class="s3">'Output shape:'</span><span class="s1">, linear(wide_window.example[</span><span class="s4">0</span><span class="s1">]).shape)</span>

<span class="s1">wide_window.plot(linear)</span>

<span class="s1">plt.bar(x = range(len(train_df.columns)),</span>
        <span class="s1">height=linear.layers[</span><span class="s4">0</span><span class="s1">].kernel[:,</span><span class="s4">0</span><span class="s1">].numpy())</span>
<span class="s1">axis = plt.gca()</span>
<span class="s1">axis.set_xticks(range(len(train_df.columns)))</span>
<span class="s1">_ = axis.set_xticklabels(train_df.columns, rotation=</span><span class="s4">90</span><span class="s1">)</span>

<span class="s0">### Dense</span>
<span class="s1">dense = tf.keras.Sequential([</span>
    <span class="s1">tf.keras.layers.Dense(units=</span><span class="s4">64</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">tf.keras.layers.Dense(units=</span><span class="s4">64</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">tf.keras.layers.Dense(units=</span><span class="s4">1</span><span class="s1">)</span>
<span class="s1">])</span>

<span class="s1">history = compile_and_fit(dense, single_step_window)</span>

<span class="s1">val_performance[</span><span class="s3">'Dense'</span><span class="s1">] = dense.evaluate(single_step_window.val)</span>
<span class="s1">performance[</span><span class="s3">'Dense'</span><span class="s1">] = dense.evaluate(single_step_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>

<span class="s0">### Multi-step dense</span>
<span class="s1">CONV_WIDTH = </span><span class="s4">3</span>
<span class="s1">conv_window = WindowGenerator(</span>
    <span class="s1">input_width=CONV_WIDTH,</span>
    <span class="s1">label_width=</span><span class="s4">1</span><span class="s1">,</span>
    <span class="s1">shift=</span><span class="s4">1</span><span class="s1">,</span>
    <span class="s1">label_columns=[</span><span class="s3">'T (degC)'</span><span class="s1">]</span>
<span class="s1">)</span>

<span class="s1">conv_window</span>

<span class="s1">conv_window.plot()</span>
<span class="s1">plt.title(</span><span class="s3">&quot;Given 3 h of inputs, predict 1 h into the future.&quot;</span><span class="s1">)</span>

<span class="s1">multi_step_dense = tf.keras.Sequential([</span>
    <span class="s0"># Shape: (time, features) =&gt; (time * features)</span>
    <span class="s1">tf.keras.layers.Flatten(),</span>
    <span class="s1">tf.keras.layers.Dense(units=</span><span class="s4">32</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">tf.keras.layers.Dense(units=</span><span class="s4">32</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">tf.keras.layers.Dense(units=</span><span class="s4">1</span><span class="s1">),</span>
    <span class="s0"># Add back the time dimension.</span>
    <span class="s0"># Shape: (outputs) =&gt; (1, outputs)</span>
    <span class="s1">tf.keras.layers.Reshape([</span><span class="s4">1</span><span class="s1">, -</span><span class="s4">1</span><span class="s1">])</span>
<span class="s1">])</span>

<span class="s1">print(</span><span class="s3">'Input shape:'</span><span class="s1">, conv_window.example[</span><span class="s4">0</span><span class="s1">].shape)</span>
<span class="s1">print(</span><span class="s3">'Output shape:'</span><span class="s1">, multi_step_dense(conv_window.example[</span><span class="s4">0</span><span class="s1">]).shape)</span>

<span class="s1">history = compile_and_fit(multi_step_dense, conv_window)</span>

<span class="s0"># IPython.display.clear_output()</span>
<span class="s1">val_performance[</span><span class="s3">'Multi step dense'</span><span class="s1">] = multi_step_dense.evaluate(conv_window.val)</span>
<span class="s1">performance[</span><span class="s3">'Multi step dense'</span><span class="s1">] = multi_step_dense.evaluate(conv_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>

<span class="s1">conv_window.plot(multi_step_dense)</span>

<span class="s1">print(</span><span class="s3">'Input shape'</span><span class="s1">, wide_window.example[</span><span class="s4">0</span><span class="s1">].shape)</span>
<span class="s2">try</span><span class="s1">:</span>
    <span class="s1">print(</span><span class="s3">'Output shape:'</span><span class="s1">, multi_step_dense(wide_window.example[</span><span class="s4">0</span><span class="s1">]).shape)</span>
<span class="s2">except </span><span class="s1">Exception </span><span class="s2">as </span><span class="s1">e:</span>
    <span class="s1">print(</span><span class="s3">f'</span><span class="s5">\n{</span><span class="s1">type(e).__name__</span><span class="s5">}</span><span class="s3">:</span><span class="s5">{</span><span class="s1">e</span><span class="s5">}</span><span class="s3">'</span><span class="s1">)</span>

<span class="s0">### CNN</span>
<span class="s1">conv_model = tf.keras.Sequential([</span>
    <span class="s1">tf.keras.layers.Conv1D(filters=</span><span class="s4">32</span><span class="s1">, kernel_size=(CONV_WIDTH,), activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">tf.keras.layers.Dense(units=</span><span class="s4">32</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">tf.keras.layers.Dense(units=</span><span class="s4">1</span><span class="s1">)</span>
<span class="s1">])</span>

<span class="s1">print(</span><span class="s3">&quot;Conv model on `conv_window`&quot;</span><span class="s1">)</span>
<span class="s1">print(</span><span class="s3">'Input shape:'</span><span class="s1">, conv_window.example[</span><span class="s4">0</span><span class="s1">].shape)</span>
<span class="s1">print(</span><span class="s3">'Output shape:'</span><span class="s1">, conv_model(conv_window.example[</span><span class="s4">0</span><span class="s1">]).shape)</span>

<span class="s1">history = compile_and_fit(conv_model, conv_window)</span>

<span class="s0"># IPython.display.clear_output()</span>
<span class="s1">val_performance[</span><span class="s3">'Conv'</span><span class="s1">] = conv_model.evaluate(conv_window.val)</span>
<span class="s1">performance[</span><span class="s3">'Conv'</span><span class="s1">] = conv_model.evaluate(conv_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>

<span class="s1">print(</span><span class="s3">&quot;Wide window&quot;</span><span class="s1">)</span>
<span class="s1">print(</span><span class="s3">'Input shape:'</span><span class="s1">, wide_window.example[</span><span class="s4">0</span><span class="s1">].shape)</span>
<span class="s1">print(</span><span class="s3">'Labels shape:'</span><span class="s1">, wide_window.example[</span><span class="s4">1</span><span class="s1">].shape)</span>
<span class="s1">print(</span><span class="s3">'Output shape:'</span><span class="s1">, conv_model(wide_window.example[</span><span class="s4">0</span><span class="s1">]).shape)</span>

<span class="s1">LABEL_WIDTH = </span><span class="s4">24</span>
<span class="s1">INPUT_WIDTH = LABEL_WIDTH + (CONV_WIDTH - </span><span class="s4">1</span><span class="s1">)</span>
<span class="s1">wide_conv_window = WindowGenerator(</span>
    <span class="s1">input_width=INPUT_WIDTH,</span>
    <span class="s1">label_width=LABEL_WIDTH,</span>
    <span class="s1">shift=</span><span class="s4">1</span><span class="s1">,</span>
    <span class="s1">label_columns=[</span><span class="s3">'T (degC)'</span><span class="s1">]</span>
<span class="s1">)</span>

<span class="s1">wide_conv_window</span>

<span class="s1">print(</span><span class="s3">&quot;Wide conv window&quot;</span><span class="s1">)</span>
<span class="s1">print(</span><span class="s3">'Input shape:'</span><span class="s1">, wide_conv_window.example[</span><span class="s4">0</span><span class="s1">].shape)</span>
<span class="s1">print(</span><span class="s3">'Labels shape:'</span><span class="s1">, wide_conv_window.example[</span><span class="s4">1</span><span class="s1">].shape)</span>
<span class="s1">print(</span><span class="s3">'Output shape:'</span><span class="s1">, conv_model(wide_conv_window.example[</span><span class="s4">0</span><span class="s1">]).shape)</span>

<span class="s1">wide_conv_window.plot(conv_model)</span>

<span class="s0">### RNN</span>
<span class="s1">lstm_model = tf.keras.models.Sequential([</span>
    <span class="s0"># Shape [batch, time, features] =&gt; [batch, time, lstm_units]</span>
    <span class="s1">tf.keras.layers.LSTM(</span><span class="s4">32</span><span class="s1">, return_sequences=</span><span class="s2">True</span><span class="s1">),</span>
    <span class="s0"># Shape =&gt; [batch, time, features]</span>
    <span class="s1">tf.keras.layers.Dense(units=</span><span class="s4">1</span><span class="s1">)</span>
<span class="s1">])</span>

<span class="s1">print(</span><span class="s3">'Input shape:'</span><span class="s1">, wide_window.example[</span><span class="s4">0</span><span class="s1">].shape)</span>
<span class="s1">print(</span><span class="s3">'Output shape:'</span><span class="s1">, lstm_model(wide_window.example[</span><span class="s4">0</span><span class="s1">]).shape)</span>

<span class="s1">history = compile_and_fit(lstm_model, wide_window)</span>

<span class="s0"># IPython.display.clear_output()</span>
<span class="s1">val_performance[</span><span class="s3">'LSTM'</span><span class="s1">] = lstm_model.evaluate(wide_window.val)</span>
<span class="s1">performance[</span><span class="s3">'LSMT'</span><span class="s1">] = lstm_model.evaluate(wide_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>

<span class="s1">wide_window.plot(lstm_model)</span>

<span class="s0">### Performance</span>
<span class="s1">x = np.arange(len(performance))</span>
<span class="s1">width = </span><span class="s4">0.3</span>
<span class="s1">metric_name = </span><span class="s3">'mean_absolute_error'</span>
<span class="s1">metric_index = lstm_model.metrics_names.index(</span><span class="s3">'mean_absolute_error'</span><span class="s1">)</span>
<span class="s1">val_mae = [v[metric_index] </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">val_performance.values()]</span>
<span class="s1">test_mae = [v[metric_index] </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">performance.values()]</span>

<span class="s1">plt.ylabel(</span><span class="s3">'mean_absolute_error [T (degC), normalized]'</span><span class="s1">)</span>
<span class="s1">plt.bar(x - </span><span class="s4">0.17</span><span class="s1">, val_mae, width, label=</span><span class="s3">'Validation'</span><span class="s1">)</span>
<span class="s1">plt.bar(x + </span><span class="s4">0.17</span><span class="s1">, test_mae, width, label=</span><span class="s3">'Test'</span><span class="s1">)</span>
<span class="s1">plt.xticks(ticks=x, labels=performance.keys(), rotation=</span><span class="s4">45</span><span class="s1">)</span>
<span class="s1">_ = plt.legend()</span>

<span class="s2">for </span><span class="s1">name, value </span><span class="s2">in </span><span class="s1">performance.items():</span>
    <span class="s1">print(</span><span class="s3">f'</span><span class="s5">{</span><span class="s1">name</span><span class="s5">:</span><span class="s3">12s</span><span class="s5">}</span><span class="s3">: </span><span class="s5">{</span><span class="s1">value[</span><span class="s4">1</span><span class="s1">]</span><span class="s5">:</span><span class="s3">0.4f</span><span class="s5">}</span><span class="s3">'</span><span class="s1">)</span>

<span class="s0">### Multi-output models</span>
<span class="s1">single_step_window = WindowGenerator(</span>
    <span class="s0"># `WindowGenerator` returns all features as labels if</span>
    <span class="s0"># you don't set the `label_columns` argument.</span>
    <span class="s1">input_width=</span><span class="s4">1</span><span class="s1">, label_width=</span><span class="s4">1</span><span class="s1">, shift=</span><span class="s4">1</span>
<span class="s1">)</span>

<span class="s1">wide_window = WindowGenerator(input_width=</span><span class="s4">24</span><span class="s1">, label_width=</span><span class="s4">24</span><span class="s1">, shift=</span><span class="s4">1</span><span class="s1">)</span>

<span class="s2">for </span><span class="s1">example_inputs, example_labels </span><span class="s2">in </span><span class="s1">wide_window.train.take(</span><span class="s4">1</span><span class="s1">):</span>
    <span class="s1">print(</span><span class="s3">f'Inputs shape (batch, time, features): </span><span class="s5">{</span><span class="s1">example_inputs.shape</span><span class="s5">}</span><span class="s3">'</span><span class="s1">)</span>
    <span class="s1">print(</span><span class="s3">f'Labels shape (batch, time, features): </span><span class="s5">{</span><span class="s1">example_labels.shape</span><span class="s5">}</span><span class="s3">'</span><span class="s1">)</span>

<span class="s0">#### Baseline</span>
<span class="s1">baseline = Baseline()</span>
<span class="s1">baseline.compile(loss=tf.keras.losses.MeanSquaredError(),</span>
                 <span class="s1">metrics=[tf.keras.metrics.MeanAbsoluteError()])</span>

<span class="s1">val_performance = {}</span>
<span class="s1">performance = {}</span>
<span class="s1">val_performance[</span><span class="s3">'Baseline'</span><span class="s1">] = baseline.evaluate(wide_window.val)</span>
<span class="s1">performance[</span><span class="s3">'Baseline'</span><span class="s1">] = baseline.evaluate(wide_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>

<span class="s0">#### Dense</span>
<span class="s1">dense = tf.keras.Sequential([</span>
    <span class="s1">tf.keras.layers.Dense(units=</span><span class="s4">64</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">tf.keras.layers.Dense(units=</span><span class="s4">64</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s1">tf.keras.layers.Dense(units=num_features)</span>
<span class="s1">])</span>

<span class="s1">history = compile_and_fit(dense, single_step_window)</span>

<span class="s0"># IPython.display.clear_output()</span>
<span class="s1">val_performance[</span><span class="s3">'Dense'</span><span class="s1">] = dense.evaluate(single_step_window.val)</span>
<span class="s1">performance[</span><span class="s3">'Dense'</span><span class="s1">] = dense.evaluate(single_step_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>

<span class="s0">#### RNN</span><hr class="ls0"><span class="s0"># %%time</span>
<span class="s1">wide_window = WindowGenerator(input_width=</span><span class="s4">24</span><span class="s1">, label_width=</span><span class="s4">24</span><span class="s1">, shift=</span><span class="s4">1</span><span class="s1">)</span>

<span class="s1">lstm_model = tf.keras.models.Sequential([</span>
    <span class="s0"># Shape [batch, time, features] =&gt; [batch, time, lstm_units]</span>
    <span class="s1">tf.keras.layers.LSTM(</span><span class="s4">32</span><span class="s1">, return_sequences=</span><span class="s2">True</span><span class="s1">),</span>
    <span class="s0"># Shape =&gt; [batch, time, features]</span>
    <span class="s1">tf.keras.layers.Dense(units=num_features)</span>
<span class="s1">])</span>

<span class="s1">history = compile_and_fit(lstm_model, wide_window)</span>

<span class="s0"># IPython.display.clear_output()</span>
<span class="s1">val_performance[</span><span class="s3">'LSTM'</span><span class="s1">] = lstm_model.evaluate(wide_window.val)</span>
<span class="s1">performance[</span><span class="s3">'LSTM'</span><span class="s1">] = lstm_model.evaluate(wide_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>

<span class="s1">print()</span>

<span class="s0">#### Advanced: Residual connections</span>
<span class="s2">class </span><span class="s1">ResidualWrapper(tf.keras.Model):</span>
    <span class="s2">def </span><span class="s1">__init__(self, model):</span>
        <span class="s1">super().__init__()</span>
        <span class="s1">self.model = model</span>

    <span class="s2">def </span><span class="s1">call(self, inputs, *args, **kwargs):</span>
        <span class="s1">delta = self.model(inputs, *args, **kwargs)</span>

        <span class="s0"># The prediction for each time step is</span>
        <span class="s0"># the input from the previous step, plus the delta (calc. by the model).</span>
        <span class="s2">return </span><span class="s1">inputs + delta</span>
<hr class="ls0"><span class="s0"># %%time</span>
<span class="s1">residual_lstm = ResidualWrapper(</span>
    <span class="s1">tf.keras.Sequential([</span>
        <span class="s1">tf.keras.layers.LSTM(</span><span class="s4">32</span><span class="s1">, return_sequences=</span><span class="s2">True</span><span class="s1">),</span>
        <span class="s1">tf.keras.layers.Dense(num_features,</span>
                              <span class="s0"># The predicted deltas should start small.</span>
                              <span class="s0"># Therefore, initialize the output layer w/ zeros.</span>
                              <span class="s1">kernel_initializer=tf.initializers.zeros())</span>
    <span class="s1">])</span>
<span class="s1">)</span>

<span class="s1">history = compile_and_fit(residual_lstm, wide_window)</span>

<span class="s0"># IPython.display.clear_output()</span>
<span class="s1">val_performance[</span><span class="s3">'Residual LSTM'</span><span class="s1">] = residual_lstm.evaluate(wide_window.val)</span>
<span class="s1">performance[</span><span class="s3">'Residual LSTM'</span><span class="s1">] = residual_lstm.evaluate(wide_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s1">print()</span>

<span class="s0">#### Performance</span>
<span class="s0"># Here is the overall performance of these multi-output models.</span>
<span class="s1">x = np.arange(len(performance))</span>
<span class="s1">width = </span><span class="s4">0.3</span>

<span class="s1">metric_name = </span><span class="s3">'mean_absolute_error'</span>
<span class="s1">metric_index = lstm_model.metrics_names.index(</span><span class="s3">'mean_absolute_error'</span><span class="s1">)</span>
<span class="s1">val_mae = [v[metric_index] </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">val_performance.values()]</span>
<span class="s1">test_mae = [v[metric_index] </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">performance.values()]</span>

<span class="s1">plt.bar(x - </span><span class="s4">0.17</span><span class="s1">, val_mae, width, label=</span><span class="s3">'Validation'</span><span class="s1">)</span>
<span class="s1">plt.bar(x + </span><span class="s4">0.17</span><span class="s1">, test_mae, width, label=</span><span class="s3">'Test'</span><span class="s1">)</span>
<span class="s1">plt.xticks(ticks=x, labels=performance.keys(),</span>
           <span class="s1">rotation=</span><span class="s4">45</span><span class="s1">)</span>
<span class="s1">plt.ylabel(</span><span class="s3">'MAE (average over all outputs)'</span><span class="s1">)</span>
<span class="s1">_ = plt.legend()</span>

<span class="s2">for </span><span class="s1">name, value </span><span class="s2">in </span><span class="s1">performance.items():</span>
  <span class="s1">print(</span><span class="s3">f'</span><span class="s5">{</span><span class="s1">name</span><span class="s5">:</span><span class="s3">15s</span><span class="s5">}</span><span class="s3">: </span><span class="s5">{</span><span class="s1">value[</span><span class="s4">1</span><span class="s1">]</span><span class="s5">:</span><span class="s3">0.4f</span><span class="s5">}</span><span class="s3">'</span><span class="s1">)</span>

<span class="s0">## Multi-step models</span>
<span class="s1">OUT_STEPS = </span><span class="s4">24</span>
<span class="s1">multi_window = WindowGenerator(input_width=</span><span class="s4">24</span><span class="s1">,</span>
                               <span class="s1">label_width=OUT_STEPS,</span>
                               <span class="s1">shift=OUT_STEPS)</span>

<span class="s1">multi_window.plot()</span>
<span class="s1">multi_window</span>

<span class="s0">### Baselines</span>
<span class="s2">class </span><span class="s1">MultiStepLastBaseline(tf.keras.Model):</span>
    <span class="s2">def </span><span class="s1">call(self, inputs):</span>
        <span class="s2">return </span><span class="s1">tf.tile(inputs[:, -</span><span class="s4">1</span><span class="s1">:, :], [</span><span class="s4">1</span><span class="s1">, OUT_STEPS, </span><span class="s4">1</span><span class="s1">])</span>

<span class="s1">last_baseline = MultiStepLastBaseline()</span>
<span class="s1">last_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),</span>
                      <span class="s1">metrics=[tf.keras.metrics.MeanAbsoluteError()])</span>

<span class="s1">multi_val_performance = {}</span>
<span class="s1">multi_performance = {}</span>

<span class="s1">multi_val_performance[</span><span class="s3">'Last'</span><span class="s1">] = last_baseline.evaluate(multi_window.val)</span>
<span class="s1">multi_performance[</span><span class="s3">'Last'</span><span class="s1">] = last_baseline.evaluate(multi_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s1">multi_window.plot(last_baseline)</span>

<span class="s2">class </span><span class="s1">RepeatBaseline(tf.keras.Model):</span>
    <span class="s2">def </span><span class="s1">call(self, inputs):</span>
        <span class="s2">return </span><span class="s1">inputs</span>

<span class="s1">repeat_baseline = RepeatBaseline()</span>
<span class="s1">repeat_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),</span>
                        <span class="s1">metrics=[tf.keras.metrics.MeanAbsoluteError()])</span>

<span class="s1">multi_val_performance[</span><span class="s3">'Repeat'</span><span class="s1">] = repeat_baseline.evaluate(multi_window.val)</span>
<span class="s1">multi_performance[</span><span class="s3">'Repeat'</span><span class="s1">] = repeat_baseline.evaluate(multi_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s1">multi_window.plot(repeat_baseline)</span>

<span class="s0">### Single-shot models</span>
<span class="s0">#### Linear</span>
<span class="s1">multi_linear_model = tf.keras.Sequential([</span>
    <span class="s0"># Take the last time-step.</span>
    <span class="s0"># Shape [batch, time, features] =&gt; [batch, 1, features]</span>
    <span class="s1">tf.keras.layers.Lambda(</span><span class="s2">lambda </span><span class="s1">x: x[:, -</span><span class="s4">1</span><span class="s1">, :]),</span>
    <span class="s0"># Shape =&gt; [batch, 1, out_steps * features]</span>
    <span class="s1">tf.keras.layers.Dense(OUT_STEPS * num_features,</span>
                          <span class="s1">kernel_initializer=tf.initializers.zeros()),</span>
    <span class="s0"># Shape =&gt; [batch, out_steps, features]</span>
    <span class="s1">tf.keras.layers.Reshape([OUT_STEPS, num_features])</span>
<span class="s1">])</span>

<span class="s1">history = compile_and_fit(multi_linear_model, multi_window)</span>

<span class="s0"># IPython.display.clear_output()</span>
<span class="s1">multi_val_performance[</span><span class="s3">'Linear'</span><span class="s1">] = multi_linear_model.evaluate(multi_window.val)</span>
<span class="s1">multi_performance[</span><span class="s3">'Linear'</span><span class="s1">] = multi_linear_model.evaluate(multi_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s1">multi_window.plot(multi_linear_model)</span>

<span class="s0">#### Dense</span>
<span class="s1">multi_dense_model = tf.keras.Sequential([</span>
    <span class="s0"># Take the last time step.</span>
    <span class="s0"># Shape [batch, time, features] =&gt; [batch, 1, features]</span>
    <span class="s1">tf.keras.layers.Lambda(</span><span class="s2">lambda </span><span class="s1">x: x[:, -</span><span class="s4">1</span><span class="s1">:, :]),</span>
    <span class="s0"># Shape =&gt; [batch, 1, dense_units]</span>
    <span class="s1">tf.keras.layers.Dense(</span><span class="s4">512</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">),</span>
    <span class="s0"># Shape =&gt; [batch, out_steps * features]</span>
    <span class="s1">tf.keras.layers.Dense(OUT_STEPS * num_features,</span>
                          <span class="s1">kernel_initializer=tf.initializers.zeros()),</span>
    <span class="s0"># Shape =&gt; [batch, out_steps, features]</span>
    <span class="s1">tf.keras.layers.Reshape([OUT_STEPS, num_features])</span>
<span class="s1">])</span>

<span class="s1">history = compile_and_fit(multi_dense_model, multi_window)</span>

<span class="s0"># IPython.display.clear_output()</span>
<span class="s1">multi_val_performance[</span><span class="s3">'Dense'</span><span class="s1">] = multi_dense_model.evaluate(multi_window.val)</span>
<span class="s1">multi_performance[</span><span class="s3">'Dense'</span><span class="s1">] = multi_dense_model.evaluate(multi_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s1">multi_window.plot(multi_dense_model)</span>

<span class="s0">#### CNN</span>
<span class="s1">CONV_WIDTH = </span><span class="s4">3</span>
<span class="s1">multi_conv_model = tf.keras.Sequential([</span>
    <span class="s0"># Shape [batch, time, features] =&gt; [batch, CONV_WIDTH, features]</span>
    <span class="s1">tf.keras.layers.Lambda(</span><span class="s2">lambda </span><span class="s1">x: x[:, -CONV_WIDTH:, :]),</span>
    <span class="s0"># Shape =&gt; [batch, 1, conv_units]</span>
    <span class="s1">tf.keras.layers.Conv1D(</span><span class="s4">256</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">, kernel_size=(CONV_WIDTH)),</span>
    <span class="s0"># Shape =&gt; [batch, 1, out_steps * features]</span>
    <span class="s1">tf.keras.layers.Dense(OUT_STEPS * num_features,</span>
                          <span class="s1">kernel_initializer=tf.initializers.zeros()),</span>
    <span class="s0"># Shape =&gt; [batch, out_steps, features]</span>
    <span class="s1">tf.keras.layers.Reshape([OUT_STEPS, num_features])</span>
<span class="s1">])</span>

<span class="s1">history = compile_and_fit(multi_conv_model, multi_window)</span>

<span class="s0"># IPhyton.display.clear_output()</span>

<span class="s1">multi_val_performance[</span><span class="s3">'Conv'</span><span class="s1">] = multi_conv_model.evaluate(multi_window.val)</span>
<span class="s1">multi_performance[</span><span class="s3">'Conv'</span><span class="s1">] = multi_conv_model.evaluate(multi_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s1">multi_window.plot(multi_conv_model)</span>

<span class="s0">#### RNN</span>
<span class="s1">multi_lstm_model = tf.keras.Sequential([</span>
    <span class="s0"># Shape [batch, time, features] =&gt; [batch, lstm_units].</span>
    <span class="s0"># Adding more 'lstm_units' just overfits more quickly.</span>
    <span class="s1">tf.keras.layers.LSTM(</span><span class="s4">32</span><span class="s1">, return_sequences=</span><span class="s2">False</span><span class="s1">),</span>
    <span class="s0"># Shape =&gt; [batch, out_steps * features].</span>
    <span class="s1">tf.keras.layers.Dense(OUT_STEPS * num_features,</span>
                          <span class="s1">kernel_initializer=tf.initializers.zeros()),</span>
    <span class="s0"># Shape =&gt; [batch, out_steps, features].</span>
    <span class="s1">tf.keras.layers.Reshape([OUT_STEPS, num_features])</span>
<span class="s1">])</span>

<span class="s1">history = compile_and_fit(multi_lstm_model, multi_window)</span>

<span class="s0"># IPython.display.clear_output()</span>

<span class="s1">multi_val_performance[</span><span class="s3">'LSTM'</span><span class="s1">] = multi_lstm_model.evaluate(multi_window.val)</span>
<span class="s1">multi_performance[</span><span class="s3">'LSTM'</span><span class="s1">] = multi_lstm_model.evaluate(multi_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s1">multi_window.plot(multi_lstm_model)</span>

<span class="s0">### Advanced: Autoregressive model</span>
<span class="s0">#### RNN</span>
<span class="s2">class </span><span class="s1">FeedBack(tf.keras.Model):</span>
    <span class="s2">def </span><span class="s1">__init__(self, units, out_steps):</span>
        <span class="s1">super().__init__()</span>
        <span class="s1">self.out_steps = out_steps</span>
        <span class="s1">self.units = units</span>
        <span class="s1">self.lstm_cell = tf.keras.layers.LSTMCell(units)</span>
        <span class="s0"># Also wrap the LSTMCell in an RNN to simplify the `warmup` method.</span>
        <span class="s1">self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">self.dense = tf.keras.layers.Dense(num_features)</span>

<span class="s1">feedback_model = FeedBack(units=</span><span class="s4">32</span><span class="s1">, out_steps=OUT_STEPS)</span>

<span class="s2">def </span><span class="s1">warmup(self, inputs):</span>
    <span class="s0"># inputs.shape =&gt; (batch, time, features)</span>
    <span class="s0"># x.shape =&gt; (batch, lstm_units)</span>
    <span class="s1">x, *state = self.lstm_rnn(inputs)</span>

    <span class="s0"># predictions.shape =&gt; (batch, features)</span>
    <span class="s1">prediction = self.dense(x)</span>
    <span class="s2">return </span><span class="s1">prediction, state</span>

<span class="s1">FeedBack.warmup = warmup</span>

<span class="s1">prediction, state = feedback_model.warmup(multi_window.example[</span><span class="s4">0</span><span class="s1">])</span>
<span class="s1">prediction.shape</span>

<span class="s2">def </span><span class="s1">call(self, inputs, training=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s0"># Use a TensorArray to capture dynamically unrolled outputs.</span>
    <span class="s1">predictions = []</span>
    <span class="s0"># Initialize the LSTM state.</span>
    <span class="s1">prediction, state = self.warmup(inputs)</span>

    <span class="s0"># Insert the first prediction.</span>
    <span class="s1">predictions.append(prediction)</span>

    <span class="s0"># Run the rest of the prediction steps.</span>
    <span class="s2">for </span><span class="s1">n </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s1">, self.out_steps):</span>
        <span class="s0"># Use the last prediction as input.</span>
        <span class="s1">x = prediction</span>
        <span class="s0"># Execute one lstm step.</span>
        <span class="s1">x, state = self.lstm_cell(x, states=state, training=training)</span>
        <span class="s0"># Convert the lstm output to a prediction.</span>
        <span class="s1">prediction = self.dense(x)</span>
        <span class="s0"># Add the prediction to the output.</span>
        <span class="s1">predictions.append(prediction)</span>

    <span class="s0"># predictions.shape =&gt; (time, batch, features)</span>
    <span class="s1">predictions = tf.stack(predictions)</span>
    <span class="s0"># predictions.shape =&gt; (batch, time, features)</span>
    <span class="s1">predictions = tf.transpose(predictions, [</span><span class="s4">1</span><span class="s1">, </span><span class="s4">0</span><span class="s1">, </span><span class="s4">2</span><span class="s1">])</span>
    <span class="s2">return </span><span class="s1">predictions</span>

<span class="s1">FeedBack.call = call</span>

<span class="s1">print(</span><span class="s3">'Output shape (batch, time, features): '</span><span class="s1">, feedback_model(multi_window.example[</span><span class="s4">0</span><span class="s1">]).shape)</span>

<span class="s1">history = compile_and_fit(feedback_model, multi_window)</span>

<span class="s0"># IPython.display.clear_output()</span>

<span class="s1">multi_val_performance[</span><span class="s3">'AR LSTM'</span><span class="s1">] = feedback_model.evaluate(multi_window.val)</span>
<span class="s1">multi_performance[</span><span class="s3">'AR LSTM'</span><span class="s1">] = feedback_model.evaluate(multi_window.test, verbose=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s1">multi_window.plot(feedback_model)</span>

<span class="s0">### Performance</span>
<span class="s1">x = np.arange(len(multi_performance))</span>
<span class="s1">width = </span><span class="s4">0.3</span>

<span class="s1">metric_name = </span><span class="s3">'mean_absolute_error'</span>
<span class="s1">metric_index = lstm_model.metrics_names.index(</span><span class="s3">'mean_absolute_error'</span><span class="s1">)</span>
<span class="s1">val_mae = [v[metric_index] </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">multi_val_performance.values()]</span>
<span class="s1">test_mae = [v[metric_index] </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">multi_performance.values()]</span>

<span class="s1">plt.bar(x - </span><span class="s4">0.17</span><span class="s1">, val_mae, width, label=</span><span class="s3">'Validation'</span><span class="s1">)</span>
<span class="s1">plt.bar(x + </span><span class="s4">0.17</span><span class="s1">, test_mae, width, label=</span><span class="s3">'Test'</span><span class="s1">)</span>
<span class="s1">plt.xticks(ticks=x, labels=multi_performance.keys(), rotation=</span><span class="s4">45</span><span class="s1">)</span>
<span class="s1">plt.ylabel(</span><span class="s3">f'MAE (average over all times &amp; outputs)'</span><span class="s1">)</span>
<span class="s1">_ = plt.legend()</span>

<span class="s2">for </span><span class="s1">name, value </span><span class="s2">in </span><span class="s1">multi_performance.items():</span>
    <span class="s1">print(</span><span class="s3">f'</span><span class="s5">{</span><span class="s1">name</span><span class="s5">:</span><span class="s3">8s</span><span class="s5">}</span><span class="s3">: </span><span class="s5">{</span><span class="s1">value[</span><span class="s4">1</span><span class="s1">]</span><span class="s5">:</span><span class="s3">0.4f</span><span class="s5">}</span><span class="s3">'</span><span class="s1">)</span>

</pre>
</body>
</html>