<html>
<head>
<title>Text_TextClassification_TFHub.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #8c8c8c; font-style: italic;}
.s1 { color: #080808;}
.s2 { color: #0033b3;}
.s3 { color: #067d17;}
.s4 { color: #1750eb;}
</style>
</head>
<body bgcolor="#ffffff">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#c0c0c0" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
Text_TextClassification_TFHub.py</font>
</center></td></tr></table>
<pre><span class="s0"># From: https://www.tensorflow.org/tutorials/keras/text_classification_with_hub</span>
<span class="s0">## Setup</span>
<span class="s0"># ! pip install tensorflow-hub</span>
<span class="s0"># ! pip install tensorflow-datasets</span>

<span class="s2">import </span><span class="s1">os</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">import </span><span class="s1">tensorflow </span><span class="s2">as </span><span class="s1">tf</span>
<span class="s2">import </span><span class="s1">tensorflow_hub </span><span class="s2">as </span><span class="s1">hub</span>
<span class="s2">import </span><span class="s1">tensorflow_datasets </span><span class="s2">as </span><span class="s1">tfds</span>

<span class="s1">print(</span><span class="s3">&quot;Version: &quot;</span><span class="s1">, tf.__version__)</span>
<span class="s1">print(</span><span class="s3">&quot;Eager mode: &quot;</span><span class="s1">, tf.executing_eagerly())</span>
<span class="s1">print(</span><span class="s3">&quot;Hub version: &quot;</span><span class="s1">, hub.__version__)</span>
<span class="s1">print(</span><span class="s3">&quot;GPU is&quot;</span><span class="s1">, </span><span class="s3">&quot;available&quot; </span><span class="s2">if </span><span class="s1">tf.config.list_physical_devices(</span><span class="s3">&quot;GPU&quot;</span><span class="s1">) </span><span class="s2">else </span><span class="s3">&quot;NOT AVAILABLE&quot;</span><span class="s1">)</span>

<span class="s0">## Download the IMDB dataset</span>
<span class="s0"># Split the training set into 60% and 40% to end up w/</span>
<span class="s0"># 15_000 ex. for training, 10_000 for validation, and 25_000 for testing.</span>
<span class="s1">train_data, validation_data, test_data = tfds.load(name=</span><span class="s3">&quot;imdb_reviews&quot;</span><span class="s1">,</span>
                                                   <span class="s1">split=(</span><span class="s3">'train[:60%]'</span><span class="s1">, </span><span class="s3">'train[60%:]'</span><span class="s1">, </span><span class="s3">'test'</span><span class="s1">),</span>
                                                   <span class="s1">as_supervised=</span><span class="s2">True</span><span class="s1">)</span>

<span class="s0">## Explore the data</span>
<span class="s1">train_examples_batch, train_labels_batch = next(iter(train_data.batch(</span><span class="s4">10</span><span class="s1">)))</span>
<span class="s1">train_examples_batch</span>

<span class="s1">train_labels_batch</span>

<span class="s0">## Build the model</span>
<span class="s1">embedding = </span><span class="s3">&quot;https://tfhub.dev/google/nnlm-en-dim50/2&quot;</span>
<span class="s1">hub_layer = hub.KerasLayer(embedding, input_shape=[],</span>
                           <span class="s1">dtype=tf.string, trainable=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s1">hub_layer(train_examples_batch[:</span><span class="s4">3</span><span class="s1">])</span>

<span class="s1">model = tf.keras.Sequential()</span>
<span class="s1">model.add(hub_layer)</span>
<span class="s1">model.add(tf.keras.layers.Dense(</span><span class="s4">16</span><span class="s1">, activation=</span><span class="s3">'relu'</span><span class="s1">))</span>
<span class="s1">model.add(tf.keras.layers.Dense(</span><span class="s4">1</span><span class="s1">))</span>

<span class="s1">model.summary()</span>

<span class="s0">### Loss function, and optimizer</span>
<span class="s1">model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=</span><span class="s2">True</span><span class="s1">),</span>
              <span class="s1">optimizer=</span><span class="s3">'adam'</span><span class="s1">,</span>
              <span class="s1">metrics=[</span><span class="s3">'accuracy'</span><span class="s1">])</span>

<span class="s0">## Train the model</span>
<span class="s1">history = model.fit(train_data.shuffle(</span><span class="s4">10_000</span><span class="s1">).batch(</span><span class="s4">512</span><span class="s1">),</span>
                    <span class="s1">epochs=</span><span class="s4">10</span><span class="s1">,</span>
                    <span class="s1">validation_data=validation_data.batch(</span><span class="s4">512</span><span class="s1">),</span>
                    <span class="s1">verbose=</span><span class="s4">1</span><span class="s1">)</span>

<span class="s0">## Evaluate the model</span>
<span class="s1">results = model.evaluate(test_data.batch(</span><span class="s4">512</span><span class="s1">),</span>
                         <span class="s1">verbose=</span><span class="s4">2</span><span class="s1">)</span>
<span class="s2">for </span><span class="s1">name, value </span><span class="s2">in </span><span class="s1">zip(model.metrics_names, results):</span>
    <span class="s1">print(</span><span class="s3">&quot;%s: %.3f&quot; </span><span class="s1">% (name, value))</span></pre>
</body>
</html>